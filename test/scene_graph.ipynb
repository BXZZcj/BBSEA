{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if '/root/BBSEA' not in sys.path:\n",
    "    sys.path.insert(0, '/root/BBSEA')\n",
    "from utils.visualization import show_box, show_mask, show_points\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from config import *\n",
    "from perception import CLIP_classify, YOLOv8, SAM\n",
    "from perception.detect_segment import crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perception.scene_graph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perception.point_cloud_utils import RGBD2PC, crop_pcd_with_labels, save_color_pc_ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=YOLOv8(YOLOv8_model_path[\"yolov8n\"])\n",
    "segmentor=SAM(\"vit_h\", SAM_model_path[\"vit_h\"])\n",
    "\n",
    "image_path=\"/root/BBSEA/images/lovers_rgb.png\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "xyxys, cls_name = detector.detect(image, visualize=True)\n",
    "print(\"the detected bboxes are:\")\n",
    "box_cls_map={tuple(k.cpu().tolist()):j for k,j in zip(xyxys, cls_name)}\n",
    "for i in box_cls_map:\n",
    "    print(f\"{i}:{box_cls_map[i]}\")\n",
    "\n",
    "masks=segmentor.segment_bbox(image, xyxys)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cls_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map=read_image(\"/root/BBSEA/images/lovers_depth.png\")[0]\n",
    "rgb_img=read_image(\"/root/BBSEA/images/lovers_rgb.png\")\n",
    "\n",
    "camera_factor, fx, fy, cx, cy = 4, 700, 700, 170.5, 109.5\n",
    "\n",
    "rgbd2pc=RGBD2PC(camera_factor, fx, fy, cx, cy)\n",
    "pointcloud=rgbd2pc.transform(depth_map=depth_map)\n",
    "# save_color_pc_ply(pointcloud=pointcloud,file_name=\"lovers_point_cloud.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pointcloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks=masks.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_pcds=crop_pcd_with_labels(pointcloud=pointcloud, masks=masks, labels=cls_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cropped_pcds[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=4\n",
    "node=Node(cropped_pcds[index][\"label\"], cropped_pcds[index][\"pointcloud\"])\n",
    "cropped_image=crop_image(Image.fromarray(image), masks[index].squeeze().cpu().numpy(), visualization=True)\n",
    "print(cropped_image)\n",
    "# state=get_object_state(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "\n",
    "from config import *\n",
    "from perception.clip_utils import CLIP_classify\n",
    "from perception.detect_segment import YOLOv8, SAM, crop_image\n",
    "from perception.point_cloud_utils import RGBD2PC, crop_pcd_with_labels\n",
    "\n",
    "# =========  Parameters for spatial relation heuristics ============\n",
    "IN_CONTACT_DISTANCE = 0.1\n",
    "INSIDE_THRESH = 0.5\n",
    "# ON_TOP_OF_THRESH = 0.7\n",
    "RELATION_EXC_OBJ_NAMES = ['drawer handle', 'catapult button']\n",
    "STATE_DICT = {\n",
    "    'drawer': ['open', 'closed'],\n",
    "    'cupboard': ['open', 'closed'],\n",
    "    'mailbox': ['open', 'closed'],\n",
    "    'catapult': ['triggered', 'not triggered']\n",
    "}\n",
    "\n",
    "# =========  Loaded Models ============\n",
    "clip_classify=CLIP_classify()\n",
    "\n",
    "\n",
    "def get_object_state(object_name, image):\n",
    "    if object_name in STATE_DICT:\n",
    "        states = STATE_DICT[object_name]\n",
    "\n",
    "        state_descriptions = [f'the {object_name} is {state}' for state in states]\n",
    "\n",
    "        return clip_classify.classify(state_descriptions, image).split()[-1]\n",
    "    return None\n",
    "\n",
    "def get_pcd_dist(pts_A, pts_B):\n",
    "    pcd_A = o3d.geometry.PointCloud()\n",
    "    pcd_A.points = o3d.utility.Vector3dVector(pts_A)\n",
    "    pcd_B = o3d.geometry.PointCloud()\n",
    "    pcd_B.points = o3d.utility.Vector3dVector(pts_B)\n",
    "\n",
    "    dists = pcd_A.compute_point_cloud_distance(pcd_B)\n",
    "    try:\n",
    "        dist = np.min(np.array(dists))\n",
    "    except:\n",
    "        dist = np.inf\n",
    "    return dist\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    if not isinstance(hull, scipy.spatial.Delaunay):\n",
    "        hull = scipy.spatial.Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "\n",
    "def is_inside(src_pts, target_pts, thresh=0.5):\n",
    "    try:\n",
    "        hull = scipy.spatial.ConvexHull(target_pts)\n",
    "    except:\n",
    "        return False\n",
    "    # print(\"vertices of hull: \", np.array(hull.vertices).shape)\n",
    "    hull_vertices = np.array([[0,0,0]])\n",
    "    for v in hull.vertices:\n",
    "        hull_vertices = np.vstack((hull_vertices, np.array([target_pts[v,0], target_pts[v,1], target_pts[v,2]])))\n",
    "    hull_vertices = hull_vertices[1:]\n",
    "\n",
    "    num_src_pts = len(src_pts)\n",
    "    # Don't want threshold to be too large (specially with more objects, like 4, 0.9*thresh becomes too large)\n",
    "    thresh_obj_particles = thresh * num_src_pts\n",
    "    src_points_in_hull = in_hull(src_pts, hull_vertices)\n",
    "    # print(\"src pts in target, thresh: \", src_points_in_hull.sum(), thresh_obj_particles)\n",
    "    if src_points_in_hull.sum() > thresh_obj_particles:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# def is_in_top_of(src_pos, target_box, thresh=0.9):\n",
    "#     upper_plane_z = np.max(target_box[:, 2]) \n",
    "#     above_count = np.sum(src_pos[:, 2] > upper_condition_z) \n",
    "#     return (above_count / len(src_pos)) >= thresh\n",
    "def is_in_top_of(src_pos, target_box):\n",
    "    upper_plane_z = np.max(target_box[:, 2])\n",
    "    return src_pos[2] > upper_plane_z  \n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, name, pcd):\n",
    "        self.name = name\n",
    "        self.pcd = pcd\n",
    "        boxes3d_pts = o3d.utility.Vector3dVector(self.pcd)\n",
    "        bbox = o3d.geometry.AxisAlignedBoundingBox.create_from_points(boxes3d_pts)\n",
    "        self.bbox = bbox # 3d bounding box\n",
    "        self.pos = bbox.get_center()\n",
    "        self.corner_pts = np.array(bbox.get_box_points())\n",
    "        self.name_w_state = None\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.name_w_state = state\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.get_name()\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.get_name())\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return True if self.get_name() == other.get_name() else False\n",
    "\n",
    "    def get_name(self):\n",
    "        if self.name_w_state is not None:\n",
    "            return self.name_w_state\n",
    "        else:\n",
    "            return self.name\n",
    "\n",
    "\n",
    "class Edge(object):\n",
    "    def __init__(self, start_node, end_node, edge_type=\"None\"):\n",
    "        self.start = start_node\n",
    "        self.end = end_node\n",
    "        self.edge_type = edge_type\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.start, self.end, self.edge_type))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if self.start == other.start and self.end == other.end and self.edge_type == other.edge_type:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.start) + \" -> \" + self.edge_type + \" -> \" + str(self.end)\n",
    "\n",
    "\n",
    "class SceneGraph(object):\n",
    "    \"\"\"\n",
    "    Create a spatial scene graph\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        self.total_nodes = []\n",
    "        self.edges = {}\n",
    "\n",
    "    def add_node(self, new_node, image):\n",
    "        for node in self.nodes:\n",
    "            self._add_edge(node, new_node)\n",
    "            # self.add_edge(new_node, node)\n",
    "        self.nodes.append(new_node)\n",
    "        self.add_object_state(new_node, image)\n",
    "\n",
    "    def _add_edge(self, node, new_node):\n",
    "        if new_node.name in RELATION_EXC_OBJ_NAMES or node.name in RELATION_EXC_OBJ_NAMES:\n",
    "            return\n",
    "        dist = get_pcd_dist(node.pcd, new_node.pcd)\n",
    "        \n",
    "        box_A_pts, box_B_pts = np.array(node.pcd), np.array(new_node.pcd)\n",
    "        box_A, box_B = node.corner_pts, new_node.corner_pts\n",
    "        pos_A, pos_B = node.pos, new_node.pos\n",
    "\n",
    "        # IN CONTACT\n",
    "        if dist < IN_CONTACT_DISTANCE:\n",
    "            if is_inside(src_pts=box_B_pts, target_pts=box_A_pts, thresh=INSIDE_THRESH):\n",
    "                self.edges[(new_node.name, node.name)] = Edge(new_node, node, \"inside\")\n",
    "            elif is_inside(src_pts=box_A_pts, target_pts=box_B_pts, thresh=INSIDE_THRESH):\n",
    "                self.edges[(node.name, new_node.name)] = Edge(node, new_node, \"inside\")\n",
    "            elif is_in_top_of(src_pos=pos_B, target_box=box_A):\n",
    "                self.edges[(new_node.name, node.name)] = Edge(new_node, node, \"on top of\")\n",
    "            elif is_in_top_of(src_pos=pos_A, target_box=box_B):\n",
    "                self.edges[(node.name, new_node.name)] = Edge(node, new_node, \"on top of\")\n",
    "    \n",
    "    def add_object_state(self, node, image):\n",
    "        state = get_object_state(node.name, image)\n",
    "        if state is not None:\n",
    "            node.set_state(f\"{node.name} ({state})\")\n",
    "        return node\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if (set(self.nodes) == set(other.nodes)) and (set(self.edges.values()) == set(other.edges.values())):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __str__(self):\n",
    "        res = \"[Nodes]:\\n\"\n",
    "        for node in self.nodes:\n",
    "            res += \"    \"\n",
    "            res += (\n",
    "            f'{node.get_name()} -- '\n",
    "            f'position: [{float(node.pos[0]):.2f}, {float(node.pos[1]):.2f}, {float(node.pos[2]):.2f}], '\n",
    "            f'x_range: [{float(node.bbox.min_bound[0]):.2f}, {float(node.bbox.max_bound[0]):.2f}], '\n",
    "            f'y_range: [{float(node.bbox.min_bound[1]):.2f}, {float(node.bbox.max_bound[1]):.2f}], '\n",
    "            f'z_range: [{float(node.bbox.min_bound[2]):.2f}, {float(node.bbox.max_bound[2]):.2f}]'\n",
    "            )\n",
    "            res += \"\\n\"\n",
    "        res += \"[Edges]:\\n\"\n",
    "        for edge_key, edge in self.edges.items():\n",
    "            res += \"    \"\n",
    "            res += str(edge)\n",
    "            res += \"\\n\"\n",
    "        return res\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Detect 2D bboxes with YOLOv8 and masks with SAM\n",
    "    detector=YOLOv8(YOLOv8_model_path[\"yolov8n\"])\n",
    "    segmentor=SAM(\"vit_h\", SAM_model_path[\"vit_h\"])\n",
    "\n",
    "    image_path=\"/root/BBSEA/images/lovers_rgb.png\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    xyxys, cls_name = detector.detect(image, visualize=True)\n",
    "    print(\"Detected objects and their bbxes:\")\n",
    "    box_cls_map={tuple(k.cpu().tolist()):j for k,j in zip(xyxys, cls_name)}\n",
    "    for i in box_cls_map:\n",
    "        print(f\"{i}:{box_cls_map[i]}\")\n",
    "\n",
    "    masks=segmentor.segment_bbox(image, xyxys)\n",
    "    masks=masks.cpu()\n",
    "\n",
    "    # Get pointclouds from the Depth Map with masks from SAM\n",
    "    depth_map=read_image(\"/root/BBSEA/images/lovers_depth.png\")[0]\n",
    "\n",
    "    camera_factor, fx, fy, cx, cy = 4, 700, 700, 170.5, 109.5\n",
    "\n",
    "    rgbd2pc=RGBD2PC(camera_factor, fx, fy, cx, cy)\n",
    "    pointcloud=rgbd2pc.transform(depth_map=depth_map)\n",
    "    cropped_pcds=crop_pcd_with_labels(pointcloud=pointcloud, masks=masks, labels=cls_name)\n",
    "\n",
    "    # Construct the SceneGraph\n",
    "    scenegraph=SceneGraph()\n",
    "    for obj_index, pcd_label in enumerate(cropped_pcds):\n",
    "        node=Node(pcd_label['label'], pcd_label['pointcloud'])\n",
    "        cropped_image=crop_image(Image.fromarray(image), masks[obj_index].squeeze().cpu().numpy())\n",
    "        scenegraph.add_node(node, cropped_image)\n",
    "    print(str(scenegraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenegraph=SceneGraph()\n",
    "for obj_index, pcd_w_label in enumerate(cropped_pcds):\n",
    "    node=Node(pcd_w_label['label'], pcd_w_label['pointcloud'])\n",
    "    cropped_image=crop_image(Image.fromarray(image), masks[obj_index].squeeze().cpu().numpy())\n",
    "    scenegraph.add_node(node, cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(scenegraph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbsea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
